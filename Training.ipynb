{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:root:Fail load requirements file, so using default ones.\n",
      "running install\n",
      "running bdist_egg\n",
      "running egg_info\n",
      "writing mask_rcnn.egg-info/PKG-INFO\n",
      "writing dependency_links to mask_rcnn.egg-info/dependency_links.txt\n",
      "writing top-level names to mask_rcnn.egg-info/top_level.txt\n",
      "reading manifest file 'mask_rcnn.egg-info/SOURCES.txt'\n",
      "reading manifest template 'MANIFEST.in'\n",
      "writing manifest file 'mask_rcnn.egg-info/SOURCES.txt'\n",
      "installing library code to build/bdist.linux-x86_64/egg\n",
      "running install_lib\n",
      "running build_py\n",
      "copying mrcnn/dataset-Copy2.py -> build/lib/mrcnn\n",
      "creating build/bdist.linux-x86_64/egg\n",
      "creating build/bdist.linux-x86_64/egg/mrcnn\n",
      "copying build/lib/mrcnn/evaluate.py -> build/bdist.linux-x86_64/egg/mrcnn\n",
      "copying build/lib/mrcnn/dataset-Copy2.py -> build/bdist.linux-x86_64/egg/mrcnn\n",
      "copying build/lib/mrcnn/parallel_model.py -> build/bdist.linux-x86_64/egg/mrcnn\n",
      "copying build/lib/mrcnn/cocoeval.py -> build/bdist.linux-x86_64/egg/mrcnn\n",
      "copying build/lib/mrcnn/utils.py -> build/bdist.linux-x86_64/egg/mrcnn\n",
      "copying build/lib/mrcnn/config.py -> build/bdist.linux-x86_64/egg/mrcnn\n",
      "copying build/lib/mrcnn/dataset-Copy1.py -> build/bdist.linux-x86_64/egg/mrcnn\n",
      "copying build/lib/mrcnn/dataset.py -> build/bdist.linux-x86_64/egg/mrcnn\n",
      "copying build/lib/mrcnn/__init__.py -> build/bdist.linux-x86_64/egg/mrcnn\n",
      "copying build/lib/mrcnn/model.py -> build/bdist.linux-x86_64/egg/mrcnn\n",
      "copying build/lib/mrcnn/visualize.py -> build/bdist.linux-x86_64/egg/mrcnn\n",
      "byte-compiling build/bdist.linux-x86_64/egg/mrcnn/evaluate.py to evaluate.cpython-36.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/mrcnn/dataset-Copy2.py to dataset-Copy2.cpython-36.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/mrcnn/parallel_model.py to parallel_model.cpython-36.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/mrcnn/cocoeval.py to cocoeval.cpython-36.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/mrcnn/utils.py to utils.cpython-36.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/mrcnn/config.py to config.cpython-36.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/mrcnn/dataset-Copy1.py to dataset-Copy1.cpython-36.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/mrcnn/dataset.py to dataset.cpython-36.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/mrcnn/__init__.py to __init__.cpython-36.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/mrcnn/model.py to model.cpython-36.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/mrcnn/visualize.py to visualize.cpython-36.pyc\n",
      "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying mask_rcnn.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying mask_rcnn.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying mask_rcnn.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying mask_rcnn.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "zip_safe flag not set; analyzing archive contents...\n",
      "creating 'dist/mask_rcnn-2.1-py3.6.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
      "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
      "Processing mask_rcnn-2.1-py3.6.egg\n",
      "Removing /opt/conda/lib/python3.6/site-packages/mask_rcnn-2.1-py3.6.egg\n",
      "Copying mask_rcnn-2.1-py3.6.egg to /opt/conda/lib/python3.6/site-packages\n",
      "mask-rcnn 2.1 is already the active version in easy-install.pth\n",
      "\n",
      "Installed /opt/conda/lib/python3.6/site-packages/mask_rcnn-2.1-py3.6.egg\n",
      "Processing dependencies for mask-rcnn==2.1\n",
      "Finished processing dependencies for mask-rcnn==2.1\n"
     ]
    }
   ],
   "source": [
    "!python3 setup.py install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "# Download and install the Python COCO tools from https://github.com/waleedka/coco\n",
    "# That's a fork from the original https://github.com/pdollar/coco with a bug\n",
    "# fix for Python 3.\n",
    "# I submitted a pull request https://github.com/cocodataset/cocoapi/pull/50\n",
    "# If the PR is merged then use the original repo.\n",
    "# Note: Edit PythonAPI/Makefile and replace \"python\" with \"python3\".\n",
    "#  \n",
    "# A quick one liner to install the library \n",
    "# !pip install git+https://github.com/waleedka/coco.git#subdirectory=PythonAPI\n",
    "\n",
    "from pycocotools.coco import COCO\n",
    "from pycocotools.cocoeval import COCOeval\n",
    "from pycocotools import mask as maskUtils\n",
    "\n",
    "from mrcnn.evaluate import build_coco_results, evaluate_coco\n",
    "from mrcnn.dataset import MappingChallengeDataset\n",
    "\n",
    "import zipfile\n",
    "import urllib.request\n",
    "import shutil\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset location \n",
    "Now we have to download all the files in the datasets section and untar them to have the following structure :\n",
    "```\n",
    "├── data\n",
    "|   ├── pretrained_weights.h5 (already included in this repository)\n",
    "│   ├── test\n",
    "│   │   └── images/\n",
    "│   │   └── annotation.json\n",
    "│   ├── train\n",
    "│   │   └── images/\n",
    "│   │   └── annotation.json\n",
    "│   └── val\n",
    "│       └── images/\n",
    "│       └── annotation.json\n",
    "```\n",
    "Note that the `pretrained_weights.h5` (available at [https://www.crowdai.org/challenges/mapping-challenge/dataset_files](https://www.crowdai.org/challenges/mapping-challenge/dataset_files)) are the weights used for the baseline submission, and are obtained by running the learning schedule mentioned later in the experiment. In the said experiment, the initial weights used can be found [here](https://github.com/matterport/Mask_RCNN/releases/download/v2.1/mask_rcnn_balloon.h5). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "ROOT_DIR = os.getcwd()\n",
    "\n",
    "# Import Mask RCNN\n",
    "sys.path.append(ROOT_DIR)  # To find local version of the library\n",
    "from mrcnn.config import Config\n",
    "from mrcnn import model as modellib, utils\n",
    "\n",
    "\n",
    "PRETRAINED_MODEL_PATH = '/data/data/crowdai/pretrained_weights.h5'\n",
    "LOGS_DIRECTORY = os.path.join(ROOT_DIR, \"logs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Configurations:\n",
      "BACKBONE                       resnet101\n",
      "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
      "BATCH_SIZE                     5\n",
      "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
      "DETECTION_MAX_INSTANCES        100\n",
      "DETECTION_MIN_CONFIDENCE       0.7\n",
      "DETECTION_NMS_THRESHOLD        0.3\n",
      "GPU_COUNT                      1\n",
      "GRADIENT_CLIP_NORM             5.0\n",
      "IMAGES_PER_GPU                 5\n",
      "IMAGE_MAX_DIM                  320\n",
      "IMAGE_META_SIZE                14\n",
      "IMAGE_MIN_DIM                  320\n",
      "IMAGE_RESIZE_MODE              square\n",
      "IMAGE_SHAPE                    [320 320   3]\n",
      "LEARNING_MOMENTUM              0.9\n",
      "LEARNING_RATE                  0.001\n",
      "MASK_POOL_SIZE                 14\n",
      "MASK_SHAPE                     [28, 28]\n",
      "MAX_GT_INSTANCES               100\n",
      "MEAN_PIXEL                     [123.7 116.8 103.9]\n",
      "MINI_MASK_SHAPE                (56, 56)\n",
      "NAME                           crowdai-mapping-challenge\n",
      "NUM_CLASSES                    2\n",
      "POOL_SIZE                      7\n",
      "POST_NMS_ROIS_INFERENCE        1000\n",
      "POST_NMS_ROIS_TRAINING         2000\n",
      "ROI_POSITIVE_RATIO             0.33\n",
      "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
      "RPN_ANCHOR_SCALES              (32, 64, 128, 256, 512)\n",
      "RPN_ANCHOR_STRIDE              1\n",
      "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
      "RPN_NMS_THRESHOLD              0.7\n",
      "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
      "STEPS_PER_EPOCH                1000\n",
      "TRAIN_BN                       False\n",
      "TRAIN_ROIS_PER_IMAGE           200\n",
      "USE_MINI_MASK                  True\n",
      "USE_RPN_ROIS                   True\n",
      "VALIDATION_STEPS               50\n",
      "WEIGHT_DECAY                   0.0001\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class MappingChallengeConfig(Config):\n",
    "    \"\"\"Configuration for training on data in MS COCO format.\n",
    "    Derives from the base Config class and overrides values specific\n",
    "    to the COCO dataset.\n",
    "    \"\"\"\n",
    "    # Give the configuration a recognizable name\n",
    "    NAME = \"crowdai-mapping-challenge\"\n",
    "\n",
    "    # We use a GPU with 12GB memory, which can fit two images.\n",
    "    # Adjust down if you use a smaller GPU.\n",
    "    IMAGES_PER_GPU = 5\n",
    "\n",
    "    # Uncomment to train on 8 GPUs (default is 1)\n",
    "    GPU_COUNT = 1\n",
    "\n",
    "    # Number of classes (including background)\n",
    "    NUM_CLASSES = 1 + 1  # 1 Backgroun + 1 Building\n",
    "\n",
    "    STEPS_PER_EPOCH=1000\n",
    "    VALIDATION_STEPS=50\n",
    "\n",
    "\n",
    "    IMAGE_MAX_DIM=320\n",
    "    IMAGE_MIN_DIM=320\n",
    "\n",
    "config = MappingChallengeConfig()\n",
    "config.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = modellib.MaskRCNN(mode=\"training\", config=config, model_dir=LOGS_DIRECTORY)\n",
    "# Load pretrained weights\n",
    "model_path = PRETRAINED_MODEL_PATH\n",
    "model.load_weights(model_path, by_name=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Training and Validation Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annotation Path  /data/data/crowdai/train/annotation-small.json\n",
      "Image Dir  /data/data/crowdai/train/images\n",
      "loading annotations into memory...\n",
      "Done (t=0.63s)\n",
      "creating index...\n",
      "index created!\n",
      "Annotation Path  /data/data/crowdai/val/annotation-small.json\n",
      "Image Dir  /data/data/crowdai/val/images\n",
      "loading annotations into memory...\n",
      "Done (t=0.06s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "# Load training dataset\n",
    "dataset_train = MappingChallengeDataset()\n",
    "dataset_train.load_dataset(dataset_dir=os.path.join(\"/data/data/crowdai\", \"train\"), load_small=True)\n",
    "dataset_train.prepare()\n",
    "\n",
    "# Load validation dataset\n",
    "dataset_val = MappingChallengeDataset()\n",
    "val_coco = dataset_val.load_dataset(dataset_dir=os.path.join(\"/data/data/crowdai\", \"val\"), load_small=True, return_coco=True)\n",
    "dataset_val.prepare()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1820"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_val.num_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# *** This training schedule is an example. Update to your needs ***\n",
    "\n",
    "# Training - Stage 1\n",
    "print(\"Training network heads\")\n",
    "model.train(dataset_train, dataset_val,\n",
    "            learning_rate=config.LEARNING_RATE,\n",
    "            epochs=40,\n",
    "            layers='heads')\n",
    "\n",
    "# Training - Stage 2\n",
    "# Finetune layers from ResNet stage 4 and up\n",
    "print(\"Fine tune Resnet stage 4 and up\")\n",
    "model.train(dataset_train, dataset_val,\n",
    "            learning_rate=config.LEARNING_RATE,\n",
    "            epochs=120,\n",
    "            layers='4+')\n",
    "\n",
    "# Training - Stage 3\n",
    "# Fine tune all layers\n",
    "print(\"Fine tune all layers\")\n",
    "model.train(dataset_train, dataset_val,\n",
    "            learning_rate=config.LEARNING_RATE / 10,\n",
    "            epochs=160,\n",
    "            layers='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can monitor the training by running : \n",
    "```\n",
    "tensorboard --logdir=logs/[path-to-your-experiment-logdir]\n",
    "```\n",
    "and if everything works great, you should see something like : \n",
    "![loss-plot](images/loss-plot.png)\n",
    "\n",
    "# Author\n",
    "Sharada Mohanty [sharada.mohanty@epfl.ch](sharada.mohanty@epfl.ch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
